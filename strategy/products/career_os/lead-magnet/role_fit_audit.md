Perfetto. Il **Role Fit Audit** deve dare una sensazione molto chiara: *“mi hanno letto nel cervello”* in 3–5 minuti, con un output **actionable** (non un test “carino”).

Qui sotto trovi una struttura **pronta da implementare in Typeform** (o Tally) + come calcolare lo score + cosa restituisci.

---

## 1) Forma del lead magnet (UX)

**Formato consigliato (v0):**

* **Typeform** (o Tally) → **Results page** immediata + invio via email del “report light”
* Tempo compilazione: **4–6 minuti**
* Domande: **18–24 max**
* Output: **Score 0–100 + archetype + 3 ruoli consigliati + next steps (7 giorni)**

**Perché così:**

* Conversione alta (veloce)
* Percepito “serio” perché restituisce *diagnosi + prescrizione*
* Ti permette follow-up e segmentazione automatica

---

## 2) Obiettivo minimo (Definition of Done)

Il Role Fit Audit è “utile” se, alla fine, l’utente ottiene:

1. **Role Fit Score** (0–100) *per 3 assi* (Code / Data / Product)
2. **Archetipo** (1 di 6) con descrizione chiara (*sei più Builder o più Analyst?*)
3. **Ruolo consigliato “NOW” + “NEXT”** (es. *RAG Dev ora, GenAI Engineer fra 2 mesi*)
4. **1 progetto flagship suggerito** (coerente col profilo)
5. **3 gap prioritari** + cosa fare nei prossimi **7 giorni**
6. CTA soft: *“Vuoi il piano personalizzato + review? Applica al Career OS”*

Se manca uno di questi, sembra un quiz.

---

## 3) Struttura del questionario (sezioni)

### A) Profilo & Vincoli (4–5 domande)

Serve per personalizzare e aumentare fiducia.

* Anni di esperienza (0 / 1–2 / 3–5 / 5+)
* Background (dev / data / STEM / altro)
* Obiettivo temporale (1–2 mesi / 3–6 / 6+)
* Italia / EU / remote (per contesto mercato)
* Disponibilità settimanale (2–4 / 4–8 / 8–12+)

**Output che abilita:** consigli “realistici” + track Start vs Pro.

---

### B) Skill Signals (core scoring) (10–12 domande)

Domande **a scala 1–5** (mai sì/no) per calcolare punteggi.

#### Asse CODE (esempi)

* “Quanto sei a tuo agio a costruire una web app con auth + DB + deploy?”
* “Quanto spesso scrivi API/backend (FastAPI/Node/…)?“
* “Sai mettere in prod una cosa con env/secrets/logs/monitoring?”
* “Test / qualità: quanto usi test, lint, typing, CI?”

#### Asse DATA (esempi)

* “Sai definire metriche e fare debug con dati reali?”
* “Quanto sei a tuo agio con retrieval, ranking, embedding, data cleaning?”
* “Hai mai fatto evaluation (anche semplice) con dataset e metriche?”

#### Asse PRODUCT/COMM (esempi)

* “Sai trasformare un problema in PRD + scope + tradeoff?”
* “Quanto sei efficace a scrivere (README, doc, write-up)?”
* “Sei a tuo agio a fare demo e difendere scelte tecniche?”

**Nota:** qui metti *pochi* tecnicismi: deve essere accessibile e non intimidire.

---

### C) GenAI Readiness (4–6 domande, “moltiplicatore”)

Non lo fare come 4° asse; usalo come **fattore che alza/abbassa** la credibilità per ruoli GenAI.

Esempi:

* “Hai già costruito qualcosa con RAG o agent (anche toy)?”
* “Sai spiegare chunking / retrieval / reranking in modo semplice?”
* “Hai mai fatto guardrails/eval (anche manuale)?”
* “Sai gestire costi, latency, privacy (anche concettualmente)?”

**Output che abilita:** “GenAI readiness: low/medium/high” + next step.

---

### D) Proof & Portfolio (3–4 domande)

Per capire se sei già “candidabile”.

* Link GitHub? (Sì/No)
* Progetto migliore (dropdown: webapp / data project / genai toy / nessuno)
* Scrivi mai contenuti? (post/articolo/README serio)
* Hai già fatto colloqui? (0 / 1–3 / 4+)

---

### E) Chiusura (1 schermata)

* “Vuoi ricevere il report in PDF light via mail?” (email)
* “Se vuoi, lascia 1 link (LinkedIn o GitHub) per una versione più precisa.” (bonus trigger)

---

## 4) Scoring: semplice ma credibile

**3 assi principali**: Code / Data / Product, ciascuno **0–100**.

**Come calcoli (v0):**

* Ogni domanda 1–5 → normalizzi in 0–100
* Media pesata per asse

**GenAI Readiness multiplier**

* Low / Mid / High (0.85 / 1.0 / 1.1)
* Applica solo al “Role Fit GenAI Score” finale, non ai tre assi.

**Output finale**

* Code score
* Data score
* Product score
* GenAI readiness
* “Best Role Now” + “Best Role Next”

---

## 5) Archetipi (6) che “suonano veri”

In base a quale asse domina + readiness:

1. **Builder** (Code alto)
2. **Analyst** (Data alto)
3. **Shipper** (Product alto + execution)
4. **Hybrid Engineer** (Code+Data bilanciati)
5. **Product-minded Builder** (Code+Product)
6. **Explorer** (assi medi/bassi: serve roadmap)

Ogni archetipo ha:

* “Punti forti”
* “Rischio principale”
* “Mossa migliore nei prossimi 7 giorni”
* “Ruolo NOW/NEXT”

---

## 6) Cosa restituisce la versione FREE (valore percepito)

**Pagina risultato immediata (scannabile):**

* 3 score + readiness
* archetipo (1 frase potente)
* 3 ruoli consigliati (con “NOW/NEXT”)
* 1 progetto consigliato (titolo + 3 bullet)
* 3 gap prioritari (max 3, non 10)
* CTA: “Vuoi il piano su misura? Applica (2 min)”

**Email report light (1 pagina)**

* stessa roba + checklist 7 giorni
* link a 1 risorsa per gap (solo 1 per gap, non 20)

Questo *già* vale anche se non comprano.

---

## 7) BONUS (per chi applica / Career OS)

Qui ci metti il tuo “unfair advantage”:

* Review manuale (LinkedIn/GitHub) con 5 bullet ultra specifici
* “Piano 14 giorni” personalizzato
* Suggested target roles + target companies starter list
* Se vuoi: **Supervised Vibe Coding setup** (questo lo leghiamo bene dopo)

---

## 8) Domande pronte (bank v0: 20)

Se vuoi, copia/incolla in Typeform.

**Profilo**

1. Esperienza: 0 / 1–2 / 3–5 / 5+
2. Background: Dev / Data / STEM / Altro
3. Obiettivo: ottenere colloqui entro… (1–2 mesi / 3–6 / 6+)
4. Ore/settimana: 2–4 / 4–8 / 8–12+

**Code (1–5)**
5) So costruire una web app con auth + DB + deploy
6) So scrivere e mantenere API/backend
7) Ho confidenza con debugging e logging in prod
8) Uso pratiche di qualità (test/lint/typing/CI)

**Data (1–5)**
9) So pulire dati e definire metriche
10) So ragionare su ranking/retrieval/embedding a livello pratico
11) So fare evaluation (anche semplice) con un set di test

**Product/Comm (1–5)**
12) So scrivere doc/README che “vendono” il progetto
13) So fare scope e tradeoff (cosa tagliare e perché)
14) So presentare una demo e difendere scelte

**GenAI readiness (1–5)**
15) Ho già costruito una cosa con RAG o agent
16) So spiegare chunking/retrieval/reranking in modo semplice
17) Ho pensato a costi/latency/privacy
18) Ho fatto guardrails o eval (anche manuale)

**Proof**
19) Hai GitHub con progetti pubblici? (Sì/No)
20) Lascia link LinkedIn o GitHub (opzionale) + email

---

## 9) Priorità implementazione (v0 in 1 sprint)

1. Typeform con 20 domande + logica base
2. calcolo score (anche manuale all’inizio: formula in sheet)
3. pagina risultati (testo statico + varianti per archetype)
4. email template “report light”
5. tag CRM: dev/data, exp, readiness, timeline, budget proxy (ore/settimana)

---
---
---

# Role Fit Audit (Lead Magnet) — Struttura v0

## Obiettivo del lead magnet

Far dire all’utente: **“mi hanno letto nel cervello”** in 4–6 minuti.

**Output minimo (DoD):**

1. **Score 0–100** su 3 assi: **Code / Data / Product**
2. **GenAI readiness**: Low / Mid / High
3. **Archetipo** (1 di 6) + descrizione breve
4. **Ruolo consigliato NOW + NEXT**
5. **3 gap prioritari** + **azione 7 giorni**
6. **1 progetto flagship consigliato**
7. CTA: **“Vuoi piano personalizzato + review? Applica al Career OS”**

---

## Sezioni del questionario (Typeform/Tally)

**Durata target:** 4–6 min • **Domande:** 18–24 • **Formato:** scale 1–5 + 2–4 scelte multiple

1. **Profilo & Vincoli** *(prima sezione — da costruire ora)*
2. Skill Signals (Code / Data / Product) *(core scoring)*
3. GenAI Readiness *(moltiplicatore credibilità)*
4. Proof & Portfolio *(candidabilità)*
5. Chiusura (email + link opzionali)

---
# Role Fit Audit (Lead Magnet) — Struttura v0

## Obiettivo del lead magnet

Far dire all’utente: **“mi hanno letto nel cervello”** in 4–6 minuti.

**Output minimo (DoD):**

1. **Score 0–100** su 3 assi: **Code / Data / Product**
2. **GenAI readiness**: Low / Mid / High
3. **Archetipo** (1 di 6) + descrizione breve
4. **Ruolo consigliato NOW + NEXT**
5. **3 gap prioritari** + **azione 7 giorni**
6. **1 progetto flagship consigliato**
7. CTA: **“Vuoi piano personalizzato + review? Applica al Career OS”**

---

## Sezioni del questionario (Typeform/Tally)

**Durata target:** 4–6 min • **Domande:** 18–24 • **Formato:** scale 1–5 + 2–4 scelte multiple

1. **Profilo & Vincoli** *(prima sezione — da costruire ora)*
2. Skill Signals (Code / Data / Product) *(core scoring)*
3. GenAI Readiness *(moltiplicatore credibilità)*
4. Proof & Portfolio *(candidabilità)*
5. Chiusura (email + link opzionali)

---

# Sezione 1 — Profilo & Vincoli (v0)

## Scopo

* Contestualizzare e personalizzare il risultato (realismo → fiducia)
* Segmentare per ICP e per offerta (Start vs Pro, 1:1 vs Cohort)
* Ridurre mismatch: dare consigli compatibili con tempo/urgenza

## Output che questa sezione abilita

* **Pacing**: “con 4–8h/sett: roadmap realistica”
* **Now vs Next**: se timeline stretta → consigli più pragmatici
* **Track suggestion**: Start (4w) vs Pro (8w)

## Domande consigliate (5)

> Nota: tutte **obbligatorie** tranne dove indicato.

### Q1 — Seniority (anni di esperienza)

**Domanda:** Quanta esperienza hai (lavoro o progetti seri)?

* 0 (student/zero exp)
* 1–2 anni
* 3–5 anni
* 5+ anni

**Uso:** segmentazione; tono e aspettative.

### Q2 — Background principale

**Domanda:** Da quale background arrivi?

* Dev (frontend/backend/fullstack)
* Data (data analyst / data scientist / ML)
* STEM (ingegneria/matematica/fisica ecc.)
* Altro

**Uso:** suggerire ruoli NOW/NEXT + messaggi.

### Q3 — Obiettivo temporale

**Domanda:** Quando vuoi iniziare ad ottenere colloqui seri su ruoli GenAI?

* 1–2 mesi
* 3–6 mesi
* 6+ mesi

**Uso:** definire aggressività del piano; Start vs Pro.

### Q4 — Tempo disponibile

**Domanda:** Quante ore a settimana puoi dedicare davvero?

* 2–4h
* 4–8h
* 8–12h
* 12h+

**Uso:** pacing; fattibilità del track; rischio drop.

### Q5 — Preferenza lavoro (contesto)

**Domanda:** Dove vuoi puntare principalmente?

* Italia
* Europa (onsite/hybrid)
* Remote internazionale
* Indifferente

**Uso:** contestualizzazione (non serve precisione salariale, solo scenario).

### Q6 (opzionale) — Stato attuale

**Domanda:** In questo momento sei…

* Studente
* Lavoro full-time
* Lavoro part-time
* In transizione / disoccupato

**Uso:** tono e supporto (energia/tempo/urgenza).

---

## Copy consigliato per la sezione (intro)

**Titolo:** “Prima: capiamo da dove parti”
**Sottotitolo:** “Ci servono 4 risposte per darti un risultato realistico (non un quiz generico).”

---

## Regole di interpretazione (v0)

* **Timeline 1–2 mesi** + **tempo ≤ 4–8h** → suggerisci **Start** o un “Pro scalato” (con avviso)
* **Tempo 8–12h+** → ok per **Pro** e progetto live
* **0 exp** → enfatizza roadmap + proof base; riduci “negoziazione”

---

## Risultati: micro-blocchi personalizzati (da usare nella pagina risultato)

In base alle risposte, aggiungi una riga “personalization”:

* “Con **{hours}/sett** e obiettivo **{timeline}**, la strategia migliore è **{strategy}**.”

Esempi strategia:

* 2–4h: “asset minimi + candidature mirate (no dispersione)”
* 4–8h: “CV+LinkedIn + 1 proof pubblica + mini-demo”
* 8–12h+: “progetto live + eval + candidatura aggressiva”

---

## Sezione 2 — Skill Signals (Code / Data / Product) + GenAI Readiness

### Obiettivo della sezione

Misurare **dove hai già segnali forti** e dove invece stai “puntando” senza fondamenta.
Questa è la sezione che alimenta il punteggio **0–100** su 3 assi:

* **Code / Engineering** (build, debug, deploy)
* **Data / ML** (dati, metriche, esperimenti)
* **Product / Delivery** (chiarezza, priorità, comunicazione)

In più aggiunge un overlay **GenAI Readiness** (RAG, eval, produzione) che serve a dire:

* *“Sei già pronto per ruoli LLM Apps?”* oppure
* *“Ti serve 2–4 settimane di fondamenta prima di inseguire agent e LangChain.”*

> Nota: questa sezione deve essere **utile sia per profili dev-centric che data/product**, quindi ogni domanda ha anche micro-segnali cross-axis.

---

### Come funziona lo scoring

**Formato consigliato (Typeform/Google Form):**

* Domande a scelta multipla (A–D)
* Ogni risposta assegna **0–3 punti** a uno o più assi
* Totale normalizzato su 100 per asse

**Pesi consigliati (per non far “vincere” chi spunta a caso):**

* **Code/Eng:** 35% della sezione
* **Data/ML:** 35% della sezione
* **Product/Delivery:** 30% della sezione

**GenAI Readiness** è un *modificatore* (non sostituisce i fondamentali):

* Se readiness è alta ma fondamentali bassi → output: “hai hype skill, manca base”
* Se readiness è media ma fondamentali buoni → output: “pronto a diventare forte in 2–4 settimane”

---

## 2A) Code / Engineering Signals (4 domande)

### Q2.1 — End-to-end building

**Domanda:** Quanto spesso costruisci qualcosa end-to-end (da zero a funzionante)?

* A) Quasi mai, faccio solo pezzi isolati → **Code +0**
* B) Ogni tanto, ma mi perdo su setup/architettura → **Code +1**
* C) Sì, riesco a chiudere un MVP con API/UI → **Code +2**
* D) Sì, e curo anche qualità (tests, error handling, logging) → **Code +3**

### Q2.2 — Debugging & qualità

**Domanda:** Quando qualcosa non funziona, come ti muovi?

* A) Provo a caso finché va → **Code +0**
* B) Loggo e cerco su Google, ma spesso perdo ore → **Code +1**
* C) Riproduco il bug, isolo la causa, fix + test → **Code +2**
* D) Oltre al fix, prevengo regressioni (test, refactor, monitoring) → **Code +3**

### Q2.3 — API & integrazioni

**Domanda:** Hai confidenza con API, auth, rate limits e integrazioni esterne?

* A) No → **Code +0**
* B) Sì ma solo seguendo tutorial → **Code +1**
* C) Sì, gestisco edge case e errori (retry, timeouts) → **Code +2**
* D) Sì, progetto integrazioni robuste (idempotenza, backoff, observability) → **Code +3**

### Q2.4 — Deploy & produzione

**Domanda:** Quanto sei pratico con deploy e ambienti reali?

* A) Mai deployato → **Code +0**
* B) Deploy “a mano”, senza config pulita → **Code +1**
* C) Deploy con env vars/secrets + basic CI → **Code +2**
* D) Deploy con CI/CD, monitoring, cost/latency awareness → **Code +3**

**Nota cross-axis:** se Q2.4 = C/D, aggiungi anche **GenAI Readiness +1** (produzione).

---

## 2B) Data / ML Signals (4 domande)

### Q2.5 — Lavorare con dati reali

**Domanda:** Quanto spesso lavori con dati “sporchi” (missing, duplicati, formati strani)?

* A) Quasi mai → **Data +0**
* B) Sì ma mi affido a notebook / tentativi → **Data +1**
* C) Sì, faccio cleaning + pipeline ripetibile → **Data +2**
* D) Sì, traccio qualità dati e faccio controlli automatizzati → **Data +3**

### Q2.6 — Metriche & valutazione

**Domanda:** Quando fai un progetto, definisci metriche e criteri di successo?

* A) No → **Data +0 / Product +0**
* B) Sì ma “a sentimento” → **Data +1 / Product +1**
* C) Sì, metriche chiare + baseline → **Data +2 / Product +1**
* D) Sì, metriche + analisi errori + iterazione → **Data +3 / Product +2**

### Q2.7 — Esperimenti e rigore

**Domanda:** Sai gestire esperimenti in modo controllato (A/B, versioning, tracking)?

* A) No → **Data +0**
* B) Un po’, ma senza disciplina → **Data +1**
* C) Sì, uso tracking/versioning (anche semplice) → **Data +2**
* D) Sì, progetto eval framework e analisi sistematiche → **Data +3**

### Q2.8 — Fondamentali ML

**Domanda:** Il tuo livello su ML basics (overfitting, bias/variance, embeddings, cosine)?

* A) Non li conosco → **Data +0**
* B) Conosco le definizioni → **Data +1**
* C) Li ho applicati in progetto → **Data +2**
* D) Li spiego e li difendo in colloquio → **Data +3**

**Nota GenAI:** se Q2.8 = C/D, aggiungi **GenAI Readiness +1** (embeddings).

---

## 2C) Product / Delivery Signals (4 domande)

### Q2.9 — Ambiguità → specifica

**Domanda:** Se ti danno un obiettivo vago (“migliora il supporto clienti”), cosa fai?

* A) Mi blocco senza requisiti → **Product +0**
* B) Chiedo chiarimenti ma poi procedo senza struttura → **Product +1**
* C) Trasformo in spec (target, scope, metriche, rischi) → **Product +2**
* D) Spec + tradeoff + piano di delivery + misurazione → **Product +3**

### Q2.10 — Comunicazione scritta

**Domanda:** Quanto sei forte nel comunicare per iscritto (doc, memo, README)?

* A) Evito → **Product +0**
* B) Scrivo, ma disorganizzato → **Product +1**
* C) Scrivo chiaro, sintetico, orientato a decisioni → **Product +2**
* D) Scrivo “da staff”: contesto, opzioni, decisione, next steps → **Product +3**

### Q2.11 — Priorità e focus

**Domanda:** Come gestisci priorità e scope quando sei sotto tempo?

* A) Provo a fare tutto → **Product +0**
* B) Taglio a caso → **Product +1**
* C) Taglio in base a impatto/rischio → **Product +2**
* D) Impatto/rischio + milestone + definizione “done” → **Product +3**

### Q2.12 — User empathy & iterazione

**Domanda:** Come validi che quello che costruisci serve davvero?

* A) Non valido → **Product +0**
* B) Chiedo feedback informale → **Product +1**
* C) Faccio test con utenti + iterazioni → **Product +2**
* D) Test + metriche + roadmap di miglioramento → **Product +3**

**Nota cross-axis:** se Q2.10 o Q2.12 = C/D, aggiungi **Code +1** *solo se* hai anche Q2.1 ≥ C (per evitare “solo slide”).

---

## 2D) GenAI Readiness (4 domande)

Queste domande non sostituiscono i fondamentali: servono a capire **quanto sei vicino a ruoli LLM Apps / Applied GenAI**.

### Q2.13 — RAG & retrieval (pratica)

**Domanda:** Hai già costruito qualcosa con retrieval (vector DB / embeddings / search)?

* A) No → **GenAI +0**
* B) Ho seguito un tutorial → **GenAI +1**
* C) Ho un mini-progetto (anche semplice) con chunking + retrieval → **GenAI +2**
* D) Ho iterato su qualità (eval, error analysis, metadata filtering) → **GenAI +3**

### Q2.14 — Prompting + tool use (agents)

**Domanda:** Sai progettare un prompt/tooling in modo ripetibile?

* A) Prompt “a caso” → **GenAI +0**
* B) Prompt template base → **GenAI +1**
* C) Prompt + strumenti (tools/function calling) con guardrail → **GenAI +2**
* D) Prompt + tools + fallback + osservabilità (logs/traces) → **GenAI +3**

### Q2.15 — Eval & qualità

**Domanda:** Come valuti la qualità di un sistema GenAI?

* A) A sentimento → **GenAI +0**
* B) Testo io manualmente → **GenAI +1**
* C) Dataset di test + metriche base → **GenAI +2**
* D) Eval suite (golden set, regression, cost/latency) → **GenAI +3**

### Q2.16 — Produzione (costi, latenza, rischi)

**Domanda:** Quanto consideri costi/latency/sicurezza in un’app GenAI?

* A) Mai → **GenAI +0**
* B) So che esistono, non li gestisco → **GenAI +1**
* C) Limito token/caching + gestione errori → **GenAI +2**
* D) Ottimizzo qualità/costo + safety/abuse + monitoring → **GenAI +3**

---

## Output atteso dalla Sezione 2 (cosa “torna fuori”)

Alla fine di questa sezione vogliamo poter generare:

1. **3 punteggi (0–100):** Code / Data / Product
2. **GenAI Readiness (0–100)**
3. **Archetipo** (esempi):

   * *Builder (Code↑, GenAI↑)*
   * *Evaluator (Data↑, GenAI↑)*
   * *Delivery Lead (Product↑, Code≥medio)*
   * *Explorer (tutti medi ma nessuno alto → serve focus)*
4. **Role Recommendation NOW/NEXT** (esempi):

   * NOW: *LLM Apps Engineer (Junior)* → NEXT: *Applied GenAI Engineer*
   * NOW: *Data Analyst → LLM Evaluation track* → NEXT: *GenAI Data/ML Engineer*
   * NOW: *Product/Delivery* → NEXT: *GenAI PM (con basi tecniche)*

---

## Evidence (opzionale ma potente per la versione BONUS)

Se vuoi aumentare il “wow” percepito (e rendere la versione premium davvero premium), aggiungi 2 campi opzionali:

* **Link GitHub / portfolio** (1 link)
* **1 progetto di cui sei più fiero** (5 righe: cosa, stack, outcome)

Nella versione FREE questi campi possono essere “facoltativi”.
Nella versione BONUS diventano input per una review manuale/assistita.


---

## Sezione 3 — Output del Role Fit Audit (Report + Raccomandazioni)

### 3.1 Obiettivo della Sezione

* Restituire un risultato **semplice da capire in 15 secondi**
* Dare **una direzione unica** (“questo è il tuo focus adesso”)
* Tradurre lo score in un **piano operativo** (anche minimale nella free)
* Creare “upgrade pull”: chi legge pensa “ok, voglio il bonus / la review umana”.

---

## 3.2 Formato dell’output (cosa riceve l’utente)

### Output FREE (instant + shareable)

**Pagina risultati (web) + mini-report (testo)**

* **Snapshot** (1 riga)
* **3 punteggi** + readiness
* **Archetipo**
* **Ruolo consigliato: NOW + NEXT**
* **Top 3 gap** + “1 azione” per gap (micro)
* **CTA soft** (scarica roadmap / applica)

> Lunghezza percepita: “schermata + 6–12 righe”.
> Deve essere forte e non “generico”.

### Output BONUS / Premium (per chi applica / entra nel Career OS)

**PDF/Notion “Audit Report completo” (2–4 pagine) + opzionale Loom 60s**

* Tutto il FREE +
* **Role Fit Matrix** dettagliata (perché sì / perché no)
* **Evidence checklist** (cosa usare per provarlo a recruiter)
* **Piano 14 giorni** (task concreti)
* **JD Targeting hint** (2-3 keyword cluster da inseguire)
* **Template CTA** (messaggio recruiter / headline LinkedIn)
* **Setup & tooling** (se inserisci anche supervised vibe coding: versione “setup” qui è oro)

> Lunghezza: 2–4 pagine max (leggibile), oppure Notion con toggle.

---

## 3.3 Struttura del Report (ordine + sezioni)

### A) “One-line diagnosis” (riga di apertura)

**Formato:**

> “Sei un **Builder** con forte asse **Code**: il tuo NOW è **LLM Apps / RAG Developer**, il NEXT è **GenAI Engineer**.”

Regole:

* **Una sola direzione primaria**, niente “dipende”.
* Inserisci NOW + NEXT per dare progressione e ridurre ansia.

---

### B) Score Snapshot (chiaro, non tecnico)

Mostra:

* Code: X/100
* Data: Y/100
* Product: Z/100
* GenAI Readiness: R/100

**Interpretazione rapida sotto (micro-legenda):**

* 0–39: base da costruire
* 40–69: job-ready “junior”
* 70–85: forte (segnali credibili)
* 86–100: raro (probabile già mid)

**Nota importantissima:** readiness NON è “quanto sei bravo”, è “quanto sei pronto a performare *nel ruolo*”.

---

### C) Archetipo (etichetta + descrizione + superpower + rischio)

Qui ti giochi il naming.

Esempio struttura:

* **Archetipo:** “Builder Pragmatico”
* **Punto forte:** “spedisci cose che funzionano”
* **Rischio:** “senza una narrativa e proof, sembri ‘solo dev’”
* **Miglior leva:** “un progetto live + 1 write-up”

**Suggerimento archetipi (8 totali, facili):**

1. Builder (Code alto)
2. Data-Driven (Data alto)
3. Product-Minded (Product alto)
4. Full-Stack Hybrid (Code+Product)
5. ML-ish (Data+Code)
6. Operator (Product medio + execution)
7. Explorer (tutto medio, readiness bassa)
8. Specialist (un asse molto alto, altri bassi)

> L’archetipo deve essere “instagrammabile”: la gente lo condivide.

---

### D) Role Recommendation (NOW + NEXT) con motivazione

Formato scannable:

**NOW (il ruolo più realistico entro 4–8 settimane)**

* Ruolo: X
* “Perché tu”: 3 bullet (basati sui punteggi)
* “Cosa serve per passare il filtro”: 3 bullet (requisiti minimi)
* “Proof richieste”: 2 asset (es: repo + demo)

**NEXT (dove puoi arrivare con il percorso completo)**

* Ruolo: Y
* “Upgrade required”: 3 bullet (gap principali)

**Esempi ruoli per il tuo ICP (Applied GenAI junior):**

* LLM Apps Developer / RAG Developer
* GenAI Engineer (applied, production)
* AI Product Engineer (ibrido)
* Applied ML / Data (se asse Data altissimo)
* Solutions Engineer (GenAI) (ottimo fallback per junior)

---

### E) Gap Radar (Top 3 gap + azione immediata)

Qui devi evitare consigli tipo “studia di più”.

Per ogni gap:

* **Gap** (etichetta concreta)
* **Perché blocca** (1 riga)
* **Fix in 7 giorni** (una cosa)
* **Evidence** (come lo dimostri)

Esempio:

* Gap: “No live demo”
* Perché blocca: “senza link sei ‘teoria’”
* Fix 7 giorni: “deploy su Firebase + pagina landing”
* Evidence: “URL + screenshot GA4”

---

### F) Next Steps (micro-piano)

FREE: **piano 7 giorni** (3 step max)

* Step 1 (30–60 min): “scegli 1 target role + 10 aziende”
* Step 2 (2–3h): “adatta CV headline + about”
* Step 3 (2–4h): “mini proof: repo skeleton + README”

BONUS: **piano 14 giorni** (più serio)

* Giorno 1–2: positioning + target list
* Giorno 3–6: proof asset (repo + demo)
* Giorno 7–10: CV tailoring + 3 candidature perfette
* Giorno 11–14: interview kit + mock

---

### G) CTA (senza essere aggressivo)

Due CTA possibili, in base allo stage:

**CTA soft (se readiness bassa):**

> “Vuoi il tuo piano personalizzato (Notion + checklist + template)? Applica per il Career OS.”

**CTA hard (se readiness alta):**

> “Hai segnali forti: con un percorso guidato ti portiamo a demo + candidature mirate. Prenota la call.”

---

## 3.4 Logica decisionale (come scegli archetipo e ruoli)

### Archetype picker (semplice)

* Se max(score) ≥ 70 → archetipo = quello dell’asse dominante
* Se 2 assi ≥ 65 e vicini → archetipo “Hybrid”
* Se tutti 40–60 → “Explorer”
* Se readiness < 45 → non consigli “GenAI Engineer” come NOW (rischio frustrazione)

### NOW vs NEXT (regola pratica)

* NOW = ruolo che richiede **proof minima** + skill stack coerente con asse dominante
* NEXT = ruolo che richiede **end-to-end ownership** (demo, deployment, eval, comms)

---

## 3.5 “Minimo utile” per far percepire valore (criterio qualità della Sezione 3)

Se l’utente finisce e pensa “ok, ho capito” allora è buono.

Checklist minimo:

* [ ] Una riga di diagnosi + direzione
* [ ] Un ruolo NOW non ambiguo
* [ ] 3 gap concreti
* [ ] 3 next steps pratici

Se manca anche uno solo → sembra un quiz da blog.

---


## 1) Archetipi (8) — naming + descrizione + superpower + rischio + leve

> Obiettivo: farli **memorabili**, *non cringe*, e abbastanza “seri” da sembrare un assessment vero.

### A1) **Builder Pragmatico** (asse dominante: Code)

* **Tagline:** “Spedisci cose che funzionano.”
* **Superpower:** execution rapido, prototipi concreti, shipping.
* **Rischio:** sembri “solo dev” se non mostri criterio (architettura, trade-off, qualità).
* **Leva #1 (proof):** demo live + README con architettura.
* **Leva #2 (posizionamento):** “I build LLM apps in production (not demos).”
* **Ruolo ideale:** LLM Apps / RAG Dev → GenAI Engineer.

### A2) **Data-Driven** (asse dominante: Data)

* **Tagline:** “Misuri prima di credere.”
* **Superpower:** ragiona per metriche, dataset, valutazione; ottimo su eval.
* **Rischio:** ti blocchi in analisi, poca prova “visibile” (demo/link).
* **Leva #1:** report + eval harness (anche semplice) con risultati.
* **Leva #2:** “I make model quality measurable.”
* **Ruolo ideale:** Applied GenAI (eval/RAG) / Applied ML → GenAI Engineer.

### A3) **Product-Minded** (asse dominante: Product)

* **Tagline:** “Sai cosa serve davvero all’utente.”
* **Superpower:** chiarezza sul problema, UX, scope, priorità.
* **Rischio:** senza proof tecnica rischi di sembrare “PM che parla”.
* **Leva #1:** case study con decisioni + demo semplice (anche no-code, ma meglio code).
* **Leva #2:** “I turn vague AI ideas into shippable products.”
* **Ruolo ideale:** AI Product Engineer / Solutions (GenAI) → GenAI Product Engineer.

### A4) **Full-Stack Hybrid** (Code + Product alti)

* **Tagline:** “Costruisci e sai raccontarlo.”
* **Superpower:** end-to-end ownership, velocità + chiarezza.
* **Rischio:** dispersione; se non scegli un ruolo, sembri generalista.
* **Leva #1:** 1 flagship project con scope chiaro (non 3 mini-progetti).
* **Leva #2:** “One product. One story. One link.”
* **Ruolo ideale:** GenAI Engineer (applied) / AI Product Engineer → Lead/Owner.

### A5) **ML-ish Applied** (Data + Code alti)

* **Tagline:** “Tra ML e software: l’incastro giusto.”
* **Superpower:** ottimo per pipeline, retrieval, eval, integrazione.
* **Rischio:** puoi cadere nel “tecnico astratto” senza output leggibile.
* **Leva #1:** notebook → report → demo (trasformare in asset).
* **Leva #2:** “I ship measurable GenAI systems.”
* **Ruolo ideale:** Applied GenAI / RAG Engineer → GenAI Engineer.

### A6) **Operator** (Product medio + execution, tutti medi ma costanti)

* **Tagline:** “Rendi l’AI utile, senza drama.”
* **Superpower:** affidabilità, delivery, organizzazione, processi.
* **Rischio:** senza un “pezzo wow” non emergi.
* **Leva #1:** playbook + small tool live (anche piccolo, ma polished).
* **Leva #2:** “I make GenAI usable for teams.”
* **Ruolo ideale:** GenAI Solutions / Implementation / Junior GenAI Engineer.

### A7) **Explorer** (tutti medi/bassi, readiness bassa)

* **Tagline:** “Hai potenziale, ti manca direzione.”
* **Superpower:** curiosità, apprendimento rapido.
* **Rischio:** fai tutto e niente; CV generico, portfolio random.
* **Leva #1:** scegliere 1 ruolo NOW + 1 progetto.
* **Leva #2:** ridurre stack, aumentare proof.
* **Ruolo ideale:** percorso “Start” prima di inseguire “GenAI Engineer”.

### A8) **Specialist** (un asse altissimo, altri bassi)

* **Tagline:** “Forte in una cosa, da bilanciare.”
* **Superpower:** profondità reale (es: backend, data, UX…)
* **Rischio:** mismatch con ruoli end-to-end se mancano le basi degli altri assi.
* **Leva #1:** “bridge skills” minime (es: se sei backend forte → UI minima + demo).
* **Leva #2:** posizionarti come “specialista applicato” con proof.
* **Ruolo ideale:** dipende dal picco: specialist → hybrid.

---

## 2) Mapping Archetipi → NOW/NEXT role (tabella + regole)

### Regola “NOW”

NOW deve essere **ottenibile** con:

* 1 progetto “flagship” (non 3)
* 1 proof pubblica (repo/demo/report)
* CV + LinkedIn coerenti

### Regola “NEXT”

NEXT richiede:

* end-to-end reliability (deploy, secrets, logging)
* storytelling tecnico
* preparazione colloqui + JD targeting

---

### Tabella mapping (consigliato per l’audit)

| Archetipo          | NOW (4-8 settimane)                                         | NEXT (8-12+ settimane)       | Asset minimi per NOW         |
| ------------------ | ----------------------------------------------------------- | ---------------------------- | ---------------------------- |
| Builder Pragmatico | **LLM Apps Dev / RAG Dev**                                  | **GenAI Engineer (Applied)** | Demo live + repo + README    |
| Data-Driven        | **Applied GenAI (Eval/RAG)** o **Applied ML (GenAI)**       | **GenAI Engineer**           | Report eval + repo (harness) |
| Product-Minded     | **AI Product Engineer (junior)** o **Solutions GenAI**      | **GenAI Product Engineer**   | Case study + demo semplice   |
| Full-Stack Hybrid  | **AI Product Engineer** o **GenAI Engineer (junior)**       | **GenAI Engineer (mid)**     | Flagship project completo    |
| ML-ish Applied     | **RAG Engineer / Applied GenAI**                            | **GenAI Engineer**           | Repo + eval + demo           |
| Operator           | **Solutions/Implementation GenAI**                          | **GenAI Engineer**           | Playbook + tool piccolo live |
| Explorer           | **Start Track: LLM Apps Dev (junior)** *ma solo dopo focus* | **RAG Dev / GenAI Engineer** | Target role + 1 progetto     |
| Specialist         | Ruolo “bridge” vicino al picco                              | Hybrid più completo          | 1 proof + 2 bridge skills    |

---

### Logica decisionale (semplice da implementare)

Usa i punteggi: Code / Data / Product + Readiness

1. **Archetipo**

* Se max asse ≥ 70 e distacco ≥ 10 → archetipo = asse dominante
* Se due assi ≥ 65 e distacco < 10 → Hybrid (Full-Stack o ML-ish)
* Se readiness < 45 → Explorer (anche se un asse è medio)

2. **NOW role**

* Code alto + Data medio → LLM Apps / RAG Dev
* Data alto + Code medio → Applied GenAI (eval/report-first)
* Product alto + Code medio → AI Product Engineer / Solutions
* Tutto medio → Operator o Explorer (con focus obbligatorio)

3. **NEXT role**

* Se readiness > 60 e almeno 2 assi > 55 → GenAI Engineer / AI Product Engineer
* Se data dominante → GenAI Engineer con forte eval

---

## 3) Template Report (FREE + BONUS) pronto da incollare

### 3A) Template Report FREE (schermata risultati)

> Questo è “instant”: chiude il loop e fa percepire valore anche se non compra.

**Titolo**
**Role Fit Audit — Risultato**

**One-line Diagnosis**

> Sei un **{ARCHETIPO}**: il tuo NOW è **{NOW_ROLE}**, il tuo NEXT è **{NEXT_ROLE}**.

**Score Snapshot**

* Code: **{CODE}/100**
* Data: **{DATA}/100**
* Product: **{PRODUCT}/100**
* GenAI Readiness: **{READINESS}/100**

**Interpretazione (micro)**

* Il tuo punto forte: **{TOP_STRENGTH}**
* Il tuo freno attuale: **{TOP_BLOCKER}**

**Role Recommendation**
**NOW (obiettivo realistico): {NOW_ROLE}**
Perché sì (3 segnali):

* {SIGNAL_1}
* {SIGNAL_2}
* {SIGNAL_3}

Cosa devi dimostrare per passare il filtro:

* {REQUIREMENT_1}
* {REQUIREMENT_2}
* {REQUIREMENT_3}

**Top 3 Gap (con fix rapido)**

1. **{GAP_1}** → Fix 7 giorni: **{FIX_1}**
2. **{GAP_2}** → Fix 7 giorni: **{FIX_2}**
3. **{GAP_3}** → Fix 7 giorni: **{FIX_3}**

**Next 7 Days (mini piano)**

* Giorno 1: {ACTION_DAY_1}
* Giorno 3: {ACTION_DAY_3}
* Giorno 7: {ACTION_DAY_7}

**CTA (soft)**

> Vuoi il report completo + piano 14 giorni + template CV/LinkedIn per il tuo ruolo? **Applica al Career OS**.

---

### 3B) Template BONUS / Premium (PDF/Notion 2–4 pagine)

> Questo è quello che “sembra consulenza”.

#### Pagina 1 — Executive Summary

**Role Fit Audit — Report Completo**

**1) Sintesi**

* Archetype: **{ARCHETIPO}**
* NOW Role: **{NOW_ROLE}**
* NEXT Role: **{NEXT_ROLE}**
* Readiness: **{READINESS}/100** (**{READINESS_LABEL}**)

**2) Il tuo vantaggio competitivo**

> {COMPETITIVE_ADVANTAGE_PARAGRAPH}
> (3 righe max, tono deciso)

**3) Quick Wins (48 ore)**

* {QUICKWIN_1}
* {QUICKWIN_2}
* {QUICKWIN_3}

---

#### Pagina 2 — Role Fit Matrix (perché sì/perché no)

**NOW Role Fit: {NOW_ROLE}**
**Perché sei un fit**

* {FIT_REASON_1}
* {FIT_REASON_2}
* {FIT_REASON_3}

**Rischi percepiti da recruiter (se non fixi)**

* {RISK_1}
* {RISK_2}
* {RISK_3}

**Evidence Checklist (se manca, perdi punti)**

* [ ] 1 link demo live
* [ ] 1 repo con README decente
* [ ] 1 write-up (anche breve) con scelte + metriche
* [ ] 3 bullet CV con numeri/risultati

---

#### Pagina 3 — Gap Plan (14 giorni)

**Top Gap #1: {GAP_1}**

* Perché blocca: {WHY_BLOCKS_1}
* Fix: {FIX_1_DETAILED}
* Output: {OUTPUT_1}
* Evidenza: {EVIDENCE_1}

**Top Gap #2: {GAP_2}**

* …

**Top Gap #3: {GAP_3}**

* …

**Piano 14 giorni (checklist)**

* Giorni 1–2: {TASKS_1_2}
* Giorni 3–6: {TASKS_3_6}
* Giorni 7–10: {TASKS_7_10}
* Giorni 11–14: {TASKS_11_14}

---

#### Pagina 4 — Posizionamento (CV/LinkedIn + outreach)

**Headline LinkedIn (3 opzioni)**

1. {HEADLINE_1}
2. {HEADLINE_2}
3. {HEADLINE_3}

**About (struttura 6 righe)**

* Riga 1: chi sei + ruolo
* Riga 2: cosa costruisci
* Riga 3: stack
* Riga 4: proof (link)
* Riga 5: target (aziende/settore)
* Riga 6: CTA (contatto)

**Template messaggio recruiter (2 varianti)**

* Variante A (diretta): {DM_A}
* Variante B (soft): {DM_B}

**Keyword cluster (per ATS/JD)**

* Cluster 1: {KW_CLUSTER_1}
* Cluster 2: {KW_CLUSTER_2}
* Cluster 3: {KW_CLUSTER_3}

---

## Extra: come “inietti” il Supervised Vibe Coding qui (se vuoi)

Sì: ci sta **perfettamente** come BONUS, perché è “setup proprietario” e crea differenziazione.

### Dove inserirlo nel report BONUS

* **Pagina 3 (Gap Plan)**: se gap = “qualità del codice / caos / architettura”
* **Appendice (Notion toggle)**: “Supervised Vibe Coding Setup”

**Snippet FREE (1 riga)**

> “Se usi AI per scrivere codice: serve un metodo supervised, altrimenti crei debito tecnico.”

**BONUS (setup) include**

* Prompting framework (3 prompt standard)
* Checklist review (10 punti)
* Regole: test-first / logging / guardrails
* Workflow: branch → PR → review
* Template per README + architecture notes

---


## 0) Output dell’Audit (cosa deve produrre)

**Numeri**

* Code (0–100)
* Data (0–100)
* Product (0–100)
* GenAI Readiness (0–100)

**Derivati (utili per consigli + gap)**

* GenAI Systems (0–100): quanto sei pronto su RAG/Agents/Eval/Deploy/Security
* Proof Score (0–100): quanta evidenza pubblica hai (repo/demo/report)

**Decisioni**

* Archetype (8)
* NOW role (realistico)
* NEXT role (step successivo)
* Top Strength (1)
* Top 3 Gap + fix 7 giorni (3)

---

## 1) Questionario: struttura (20 domande, 4–6 minuti)

> È “brutale ma veloce”. 20 è un buon trade-off: abbastanza serio, non troppo lungo.

### Sezioni

1. Profilo & Obiettivo (Q1–Q2)
2. Engineering (Q3–Q7) → Code
3. Data/ML (Q8–Q10) → Data
4. Product & Comunicazione (Q11–Q13) → Product (+ readiness)
5. GenAI Systems (Q14–Q19) → GenAI Systems (+ readiness)
6. Proof pubblica (Q20) → Proof Score (+ readiness)

---

## 2) Scoring: regole semplici e implementabili

### Scala risposta

Per quasi tutte le domande: **0–4 punti** (5 livelli).

### Normalizzazione

Per ogni dimensione:

* `score_dim = round( sum(points_dim) / max_points_dim * 100 )`

### Pesi

* Code: somma punti da Q3–Q7
* Data: somma punti da Q8–Q10
* Product: somma punti da Q11–Q13
* Readiness: somma punti da (Q7 + Q13 + Q17 + Q18 + Q19 + Q20) *(cioè qualità, comunicazione, eval, deploy, security, proof)*
* GenAI Systems: somma punti da Q14–Q19
* Proof Score: Q20

> Nota: Readiness non misura “conoscenza”, misura **capacità di essere assunto** (proof + qualità + deploy + eval).

---

## 3) Le 20 domande con mapping punti → dimensioni

### Q1 — Seniority (metadato + piccolo boost readiness)

**Anni di esperienza:** 0 / 1 / 2–3 / 4–5 / 6+

* readiness: 0 / 1 / 2 / 3 / 4

### Q2 — Obiettivo target (metadato)

**Quale ruolo vuoi puntare nei prossimi 3 mesi?**

* LLM Apps Dev / RAG Dev / GenAI Engineer / Applied GenAI (eval) / AI Product Engineer / Solutions GenAI / Non so

---

### Engineering → Code (Q3–Q7)

**Q3 — Coding confidence (0–4)**

* Code +0..4

**Q4 — Backend/API**

* “Mai” (0) / “Toy” (1) / “API semplici” (2) / “API prod con auth/db” (3) / “Prod + scaling/monitoring” (4)
* Code +0..4, Readiness +0..2 (se 3–4)

**Q5 — Frontend / UI**

* 0..4
* Code +0..2 (max 2), Product +0..2 (max 2) *(UI aiuta anche product)*

**Q6 — Git & workflow**

* “Non uso git” (0) / “solo commit” (1) / “branch + PR” (2) / “PR + code review” (3) / “PR + CI + release” (4)
* Readiness +0..4, Code +0..2 (se 2+)

**Q7 — Testing & quality**

* “mai” (0) / “sporadico” (1) / “unit test base” (2) / “unit+integration” (3) / “test + lint + quality gates” (4)
* Readiness +0..4, Code +0..2 (se 2+)

---

### Data/ML → Data (Q8–Q10)

**Q8 — SQL / data wrangling**

* 0..4
* Data +0..4

**Q9 — ML fundamentals**

* “nulla” (0) / “teoria base” (1) / “training base” (2) / “metriche + overfitting + CV” (3) / “ho applicato in progetti” (4)
* Data +0..4

**Q10 — Esperimenti / metriche**

* “non misuro” (0) / “qualitativo” (1) / “metriche base” (2) / “A/B o eval strutturata” (3) / “eval harness ripetibile” (4)
* Data +0..4, Readiness +0..2 (se 3–4)

---

### Product & Comunicazione → Product (Q11–Q13)

**Q11 — Problem framing**

* “mi serve sempre il task definito” (0) … “so definire problema, vincoli, metriche” (4)
* Product +0..4

**Q12 — User value & scope**

* 0..4
* Product +0..4

**Q13 — Writing / storytelling tecnico**

* “non scrivo” (0) / “scrivo confuso” (1) / “README base” (2) / “README + decision log” (3) / “write-up chiaro con trade-off” (4)
* Product +0..2, Readiness +0..4

---

### GenAI Systems → GenAI Systems (Q14–Q19)

**Q14 — RAG in pratica**

* “mai” (0) / “tutorial” (1) / “progetto toy” (2) / “RAG con chunking/embeddings” (3) / “RAG con eval + guardrails” (4)
* GenAI +0..4

**Q15 — Prompting & structured outputs**

* 0..4
* GenAI +0..4

**Q16 — Agents / tool calling**

* 0..4
* GenAI +0..4

**Q17 — Eval LLM**

* “mai” (0) / “solo impressione” (1) / “test manuale” (2) / “metriche + set di test” (3) / “eval harness + regressioni” (4)
* GenAI +0..4, Readiness +0..4

**Q18 — Deploy (cloud + env + secrets)**

* 0..4
* GenAI +0..2, Readiness +0..4 *(deploy = readiness)*

**Q19 — Security / PII / cost control**

* 0..4
* GenAI +0..2, Readiness +0..4

---

### Proof → Proof Score (Q20)

**Q20 — Evidenza pubblica oggi**

* “nulla” (0)
* “1 repo incompleto” (1)
* “1 repo decente” (2)
* “repo + README + demo/host” (3)
* “demo live + report/eval + write-up” (4)
* Proof +0..4, Readiness +0..4

---

## 4) Regole per Archetype (8)

> Le soglie sono pensate per junior/early. Vanno bene per partire e poi le tarerai con i dati.

**Step 1 — Se readiness < 45 → Explorer (A7)**
(perché anche se sai, non sei “presentabile”)

**Step 2 — Dominanze**

* `top = max(Code, Data, Product)`
* se `top - second >= 12` → dominante
* se `top >= 70` e `second < 50` → Specialist (A8)

**Step 3 — Archetype**

* Code dominante → **Builder Pragmatico (A1)**
* Data dominante → **Data-Driven (A2)**
* Product dominante → **Product-Minded (A3)**
* Code + Product alti (>=65 entrambi) → **Full-Stack Hybrid (A4)**
* Code + Data alti (>=65 entrambi) → **ML-ish Applied (A5)**
* Tutti medi (45–65) + readiness >=50 → **Operator (A6)**

---

## 5) Regole NOW / NEXT role

Usa **Archetype + GenAI Systems + Readiness**.

### NOW role

* A1 (Builder) + GenAI>=55 → **LLM Apps Dev / RAG Dev**
* A2 (Data-Driven) + GenAI>=55 → **Applied GenAI (Eval/RAG)**
* A3 (Product) + GenAI>=45 → **AI Product Engineer (junior)** o **Solutions GenAI**
* A4 (Full-Stack) + GenAI>=55 → **GenAI Engineer (junior)** / **AI Product Engineer**
* A5 (ML-ish) + GenAI>=60 → **RAG Engineer / Applied GenAI**
* A6 (Operator) + GenAI>=45 → **Solutions/Implementation GenAI**
* A7 (Explorer) → **Start Track** (prima focus + 1 proof)
* A8 (Specialist) → **Bridge role** vicino al picco (es: backend→LLM apps; data→eval)

### NEXT role

* Se readiness >= 60 e GenAI >= 60 e (Code >=55 + (Data>=50 o Product>=50))
  → **GenAI Engineer (Applied)** / **AI Product Engineer**
* Se Data >=70 e GenAI >=60 → **GenAI Engineer con focus Eval**
* Se Product >=70 e Code >=55 → **AI Product Engineer**

---

## 6) Response Library (stringhe pronte)

### 6.1 Readiness label

* 0–44: **Not Ready Yet**
* 45–59: **Early Ready**
* 60–74: **Interview Ready**
* 75–100: **Production Ready**

### 6.2 One-line diagnosis (per archetype)

* A1: “Sei un **Builder Pragmatico**: sai costruire, ora devi trasformare output in **proof pubblica**.”
* A2: “Sei **Data-Driven**: il tuo vantaggio è la **misurabilità**; ti serve un asset più ‘visibile’ (demo/link).”
* A3: “Sei **Product-Minded**: sai scegliere cosa conta; ti serve 1 progetto che dimostri **execution tecnico**.”
* A4: “Sei **Full-Stack Hybrid**: end-to-end naturale; serve **focus** su un ruolo e un flagship project.”
* A5: “Sei **ML-ish Applied**: forte sull’incastro data+code; spingi su **eval + deploy** per diventare credibile.”
* A6: “Sei **Operator**: affidabile e concreto; ti manca un **pezzo wow** per emergere.”
* A7: “Sei **Explorer**: potenziale alto, direzione bassa; la priorità è **scegliere 1 ruolo** e costruire 1 proof.”
* A8: “Sei **Specialist**: profondità reale; aggiungi 1–2 bridge skills per essere spendibile su ruoli GenAI applied.”

### 6.3 Strength mapping (top dimension)

* Top=Code → “Execution e problem solving tecnico”
* Top=Data → “Ragionamento per metriche e qualità”
* Top=Product → “Chiarezza su problema, scope e impatto”
* Top=Readiness → “Affidabilità: sai portare in produzione e presentarti bene”

---

## 7) Gap engine: top 3 gap + fix 7 giorni (regole)

> Prendi i gap in ordine di priorità in base a soglie. Ti lascio 10 gap “canonici”.

### Regole di selezione (semplici)

* se ProofScore <= 50 → includi **GAP_PROOF**
* se GenAI Systems < 55 → includi **GAP_GENAI_FOUNDATION**
* se Readiness < 60 → includi **GAP_SHIPPING**
* se Code < 55 → includi **GAP_ENGINEERING**
* se Data < 50 → includi **GAP_EVAL_DATA**
* se Product < 50 → includi **GAP_STORY_SCOPE**
* se (Code alto ma Product basso) → **GAP_NARRATIVE**
* se (Product alto ma Code basso) → **GAP_IMPLEMENTATION**
* se Test/Quality basso (Q7 <=1) → **GAP_QUALITY**
* se Deploy basso (Q18 <=1) → **GAP_DEPLOY**

### Gap definitions (con fix 7 giorni + output)

**GAP_PROOF — “Non hai evidenza pubblica”**

* Fix 7 giorni:

  1. scegli 1 mini-tool (RAG o agent semplice)
  2. repo pulito + README 1 pagina
  3. demo (anche minimale)
* Output: `Repo + README + link demo`

**GAP_SHIPPING — “Works on my machine”**

* Fix: deploy + env/secrets + logging base
* Output: `HTTPS live + env template + basic logs`

**GAP_GENAI_FOUNDATION — “GenAI conoscenza frammentata”**

* Fix: 1 RAG end-to-end con chunking + retriever + rerank (se possibile)
* Output: `Doc architettura + small eval set + risultati`

**GAP_EVAL_DATA — “Non misuri qualità”**

* Fix: crea 20 query di test + rubric + metriche base
* Output: `Eval sheet + report`

**GAP_ENGINEERING — “Fondamenta engineering deboli”**

* Fix: API + struttura progetto + error handling + tests minimi
* Output: `Backend repo con test + doc usage`

**GAP_STORY_SCOPE — “Non sai raccontare cosa hai fatto”**

* Fix: write-up (problema → approccio → trade-off → risultati)
* Output: `1 pagina case study (blog/README)`

**GAP_QUALITY — “Mancano test e standard”**

* Fix: lint + formatter + unit test su 2 funzioni critiche
* Output: `CI pass + badge + test`

**GAP_DEPLOY — “Niente cloud”**

* Fix: deploy su Vercel/Firebase/Render + secrets
* Output: `Link + deploy guide`

**GAP_NARRATIVE — “Sei tecnico ma sembri ‘solo dev’”**

* Fix: evidenzia impatto + decisioni + metriche
* Output: `CV bullets + README ‘decision log’`

**GAP_IMPLEMENTATION — “Hai idee ma poca execution”**

* Fix: skeleton app + feature core + demo
* Output: `Demo + repo`

---

## 8) Config “implementabile” (pseudo-JSON + logica)

Se vuoi, puoi copiare questo schema e poi lo trasformi in codice.

```json
{
  "dimensions": ["code", "data", "product", "readiness", "genai", "proof"],
  "questions": {
    "Q7": { "maps": {"readiness": [0,1,2,3,4], "code": [0,0,1,2,2]} },
    "Q17": { "maps": {"genai": [0,1,2,3,4], "readiness": [0,1,2,3,4]} },
    "Q20": { "maps": {"proof": [0,1,2,3,4], "readiness": [0,1,2,3,4]} }
  },
  "archetype_rules": [
    { "if": "readiness < 45", "then": "EXPLORER" },
    { "if": "code>=65 && product>=65", "then": "FULL_STACK_HYBRID" },
    { "if": "code>=65 && data>=65", "then": "ML_ISH_APPLIED" },
    { "if": "top_dim=='code' && (code-second)>=12", "then": "BUILDER" },
    { "if": "top_dim=='data' && (data-second)>=12", "then": "DATA_DRIVEN" },
    { "if": "top_dim=='product' && (product-second)>=12", "then": "PRODUCT_MINDED" },
    { "if": "all_between(45,65) && readiness>=50", "then": "OPERATOR" },
    { "else": "SPECIALIST_OR_HYBRID" }
  ]
}
```

---


## 1) Questionario Typeform — 20 domande (copy pronto)

### Sezione 1 — Profilo & Obiettivo (2)

**Q1 — Esperienza**

> Quanti anni di esperienza hai in ambito dev/data?

**Q2 — Traguardo (3 mesi)**

> Nei prossimi 3 mesi, qual è il ruolo GenAI che vuoi puntare?

---

### Sezione 2 — Engineering (5)

**Q3 — Coding**

> Quanto ti senti solido/a a scrivere codice “senza tutorial” (feature vere, non esercizi)?

**Q4 — Backend / API**

> Quanta esperienza hai con backend/API (anche semplici)?

**Q5 — Frontend / UI**

> Quanto sei a tuo agio a costruire una UI “presentabile” (anche minimale)?

**Q6 — Git & collaborazione**

> Come lavori di solito con Git?

**Q7 — Qualità (test & standard)**

> Quanto applichi test, linting e standard di qualità?

---

### Sezione 3 — Data / ML (3)

**Q8 — SQL & dati**

> Quanto sei a tuo agio con SQL e manipolazione dati?

**Q9 — Fondamenti ML**

> Quanto ti senti solido/a su concetti ML fondamentali (metriche, overfitting, validation)?

**Q10 — Misurazione / esperimenti**

> Quanto sei abituato/a a misurare i risultati (metriche, test set, esperimenti)?

---

### Sezione 4 — Product & Comunicazione (3)

**Q11 — Problem framing**

> Quanto ti viene naturale definire problema, vincoli e metrica di successo?

**Q12 — Scope & impatto**

> Quanto sai scegliere “cosa costruire” (priorità, scope, trade-off) senza perderti?

**Q13 — Writing tecnico**

> Quanto sei bravo/a a spiegare un progetto (README, write-up, decisioni, risultati)?

---

### Sezione 5 — GenAI Systems (6)

**Q14 — RAG**

> Hai già costruito qualcosa con RAG (retrieval + risposta)?

**Q15 — Prompting & output strutturato**

> Quanto sei a tuo agio con prompting, tool/function calling e output strutturati (JSON)?

**Q16 — Agents**

> Hai esperienza con agenti (multi-step + strumenti + memoria)?

**Q17 — Eval LLM**

> Quanto valuti la qualità di un sistema LLM (test set, rubric, regressioni)?

**Q18 — Deploy (cloud + secrets)**

> Sai mettere online un progetto (deploy) gestendo env/secrets?

**Q19 — Affidabilità (cost/security/PII)**

> Quanto consideri aspetti reali: cost control, rate limits, PII, sicurezza?

---

### Sezione 6 — Proof pubblica (1)

**Q20 — Evidenza oggi**

> Ad oggi, quanta “proof pubblica” hai che un hiring manager può vedere subito? (repo/demo/report)

---

## 2) Opzioni risposta (5 livelli) + punteggio (0–4)

> Puoi usare **lo stesso formato** per tutte le domande, cambiando solo le descrizioni.
> Ti metto qui le opzioni *già scritte*, con **punteggio tra parentesi**.

### Q1 — Esperienza (metadato + readiness)

* 0 anni / sto iniziando (0)
* ~1 anno (1)
* 2–3 anni (2)
* 4–5 anni (3)
* 6+ anni (4)

### Q2 — Ruolo target (metadato, no punteggio)

* LLM Apps Dev (webapp + LLM)
* RAG Dev (retrieval + sistemi)
* GenAI Engineer (end-to-end)
* Applied GenAI (eval/quality)
* AI Product Engineer (tech + product)
* Solutions / Implementation GenAI
* Non sono sicuro/a (→ utile per output)

---

### Engineering

**Q3 — Coding**

* Mi blocco spesso senza guida (0)
* Riesco su task piccoli (1)
* Riesco su feature medie (2)
* Riesco su feature complesse + debug (3)
* Riesco anche a strutturare bene il progetto (4)

**Q4 — Backend / API**

* Mai fatto backend/API (0)
* Ho provato tutorial o toy API (1)
* Ho costruito API semplici (2)
* Ho fatto API “vere” con auth/db (3)
* Ho esperienza prod: logging/monitoring/scaling (4)

**Q5 — Frontend / UI**

* Non so fare UI (0)
* UI molto grezze (1)
* UI semplice ma pulita (2)
* UI buona + componenti riusabili (3)
* UI ottima + DX/UX curata (4)

**Q6 — Git & workflow**

* Non uso Git (0)
* Uso Git solo per commit (1)
* Branch + merge base (2)
* PR + code review (3)
* PR + CI + release/versioning (4)

**Q7 — Qualità (test & standard)**

* Non faccio test / standard (0)
* Rare volte (1)
* Unit test base (2)
* Unit + integration test (3)
* Test + lint + quality gates/CI (4)

---

### Data/ML

**Q8 — SQL & dati**

* Non uso SQL (0)
* Query base (1)
* Join + aggregazioni ok (2)
* Query complesse + pulizia dati (3)
* Ottimo: performance + modeling + pipeline (4)

**Q9 — Fondamenti ML**

* Quasi zero (0)
* Teoria base (1)
* Ho fatto training base (2)
* Capisco metriche/overfitting/CV (3)
* Ho applicato in progetti con ragionamento (4)

**Q10 — Misurazione / esperimenti**

* Non misuro (0)
* Solo “a sensazione” (1)
* Metriche base (2)
* Test set + metriche strutturate (3)
* Eval ripetibile (harness) + regressioni (4)

---

### Product & comunicazione

**Q11 — Problem framing**

* Mi serve task super definito (0)
* Riesco a chiarire solo a metà (1)
* Definisco problema e requisiti base (2)
* Definisco vincoli + metrica + trade-off (3)
* Sono forte: scope chiaro e misurabile (4)

**Q12 — Scope & impatto**

* Mi perdo facilmente nello scope (0)
* Faccio fatica a scegliere priorità (1)
* Priorità ok su progetti piccoli (2)
* So scegliere feature “core” e tagliare il resto (3)
* So massimizzare impatto con focus (4)

**Q13 — Writing tecnico**

* Non scrivo (0)
* Scrivo poco e confuso (1)
* README base (2)
* README + spiegazione decisioni (3)
* Write-up chiaro con trade-off + risultati (4)

---

### GenAI Systems

**Q14 — RAG**

* Mai fatto (0)
* Ho visto tutorial (1)
* Ho fatto un toy project (2)
* Ho costruito RAG con chunking/embeddings (3)
* RAG con eval + guardrails/quality (4)

**Q15 — Prompting & output strutturato**

* Prompt “a caso” (0)
* Prompt base (1)
* Prompt + output strutturato (2)
* Tool/function calling + schema robusto (3)
* Robustezza: fallback, parsing, controlli (4)

**Q16 — Agents**

* Mai (0)
* Ho provato un template (1)
* Multi-step semplice (2)
* Tool orchestration buona (3)
* Agent affidabile con controlli/eval (4)

**Q17 — Eval LLM**

* Mai valutato (0)
* Solo impressione (1)
* Test manuale con esempi (2)
* Test set + rubric + metriche (3)
* Harness + regressioni + tracking (4)

**Q18 — Deploy**

* Mai deployato (0)
* Deploy solo locale / non stabile (1)
* Deploy base (2)
* Deploy + env/secrets + logging (3)
* Deploy + monitoring + best practices (4)

**Q19 — Cost/Security/PII**

* Non ci penso (0)
* Ci penso “a parole” (1)
* Ho controlli base (2)
* Ho strategie (rate limit, caching, PII) (3)
* Ho un approccio robusto + policy (4)

---

### Proof

**Q20 — Evidenza pubblica**

* Nulla di visibile (0)
* 1 repo incompleto (1)
* 1 repo decente (2)
* Repo + README + demo (3)
* Demo live + report/eval + write-up (4)

---

## 3) Esempi report completi (FREE + BONUS)

> Qui faccio due profili “realistici” per junior:
> **(A) Builder Pragmatico** e **(B) Data-Driven**.

---

# Report Esempio A — Archetype: Builder Pragmatico

## FREE Report (quello che riceve subito)

### Snapshot

* **Archetipo:** Builder Pragmatico (Execution forte)
* **Readiness:** Early Ready (58/100)
* **Punteggi:**

  * Code: 74/100
  * Data: 41/100
  * Product: 52/100
  * GenAI Systems: 49/100
  * Proof: 40/100

### Diagnosi (1 frase)

Hai capacità di costruire, ma oggi ti manca **proof pubblica** e un minimo di **GenAI systems + eval** per essere credibile per un ruolo Applied GenAI.

### Ruolo consigliato (NOW)

**LLM Apps Dev (junior) / RAG Dev (junior)**
Motivo: il tuo punto forte è l’esecuzione end-to-end. Serve “incastrarla” su un progetto GenAI dimostrabile.

### 3 Gap prioritari (con fix 7 giorni)

1. **Proof pubblica troppo bassa**

   * Fix: repo pulito + README 1 pagina + demo (anche minimale).
2. **GenAI Systems (RAG/Agents) frammentati**

   * Fix: 1 RAG end-to-end (retrieval + risposta) con dataset piccolo.
3. **Eval quasi assente**

   * Fix: crea 20 query di test + rubric semplice (pass/fail + note).

### Prossimo passo consigliato

Se vuoi essere “candidabile”, il passo più veloce è: **1 progetto piccolo ma reale** con **demo + README + mini-eval**.

---

## BONUS Report (solo per chi applica / entra nel Career OS)

### Roadmap 14 giorni (con deliverable)

**Giorni 1–2: Setup**

* Repo template + struttura cartelle + env example
* Deliverable: `Repo skeleton + README outline`

**Giorni 3–6: RAG MVP**

* Caricamento docs + chunking + embeddings + retrieval
* Deliverable: `RAG working locally`

**Giorni 7–9: Eval**

* 20 query test + rubric + risultati in tabella
* Deliverable: `Eval sheet + report 1 pagina`

**Giorni 10–12: Deploy**

* Deploy + secrets + logging base
* Deliverable: `Demo live (HTTPS)`

**Giorni 13–14: Packaging**

* README “killer” (problema → architettura → trade-off → risultati → link)
* Deliverable: `README final + screenshot/demo`

### Template pronto: README “killer” (outline)

1. Problema (2 righe)
2. Cosa fa il sistema
3. Architettura (schema semplice)
4. Scelte tecniche (3 trade-off)
5. Eval (test set + risultati)
6. Deploy (link + istruzioni)
7. Next improvements

### Ruolo NEXT (se completi)

**GenAI Engineer (junior) / AI Product Engineer (junior)**
Condizione: demo live + eval + write-up = credibilità.

---

# Report Esempio B — Archetype: Data-Driven

## FREE Report

### Snapshot

* **Archetipo:** Data-Driven (metriche + ragionamento)
* **Readiness:** Early Ready (54/100)
* **Punteggi:**

  * Code: 48/100
  * Data: 76/100
  * Product: 45/100
  * GenAI Systems: 55/100
  * Proof: 35/100

### Diagnosi (1 frase)

Hai ottimo mindset da valutazione e qualità, ma oggi ti manca **execution visibile** (demo/repo) e un minimo di **packaging** per convincere.

### Ruolo consigliato (NOW)

**Applied GenAI (Eval/RAG) junior** oppure **RAG Dev (focus qualità)**
Motivo: il tuo vantaggio è misurare e ragionare per metriche: segnali rari e preziosi.

### 3 Gap prioritari (con fix 7 giorni)

1. **Proof pubblica**

   * Fix: “eval report” pubblico + repo minimale.
2. **Code execution (API/deploy)**

   * Fix: un wrapper API semplice + deploy base.
3. **Storytelling tecnico**

   * Fix: write-up 1 pagina (decisioni + risultati).

### Prossimo passo consigliato

Il modo più veloce per trasformare “competenza” in “assunzione” è: **eval report + demo minimale**.

---

## BONUS Report

### Roadmap 10 giorni (data-first)

**Giorni 1–2: Definisci rubric**

* Cosa significa “buono” per output LLM
* Deliverable: `Rubric + 20 test query`

**Giorni 3–5: Eval harness**

* Script o notebook che lancia test e salva risultati
* Deliverable: `Eval harness + report`

**Giorni 6–7: Mini RAG + baseline**

* RAG semplice per avere baseline comparabile
* Deliverable: `Baseline vs Improved (numeri)`

**Giorni 8–10: Packaging & deploy**

* Repo + README + demo piccola
* Deliverable: `Public proof + link`

### Asset premium incluso (solo per Career OS)

* Template “Eval Matrix” (foglio standard)
* Checklist “what to measure” per RAG/Agents
* Script base per tracking regressioni

### Ruolo NEXT (se completi)

**GenAI Engineer con focus Eval / Quality**
Perché: pochi junior portano “misura + evidenza”.

---

## Extra: output “da form” (se vuoi renderlo super automatico)

Se in Typeform vuoi far apparire “risultato immediato”, puoi usare questo blocco standard:

* Titolo: `Il tuo archetipo: {{archetype}}`
* Righe:

  * `Readiness: {{readiness_label}} ({{readiness_score}}/100)`
  * `Top strength: {{top_strength}}`
  * `NOW role: {{now_role}}`
  * `Top gaps: {{gap1}}, {{gap2}}, {{gap3}}`
  * CTA: `Vuoi il piano 14 giorni + template? Applica al Career OS.`

---


Perfetto. Qui sotto trovi **la “tabella di calcolo” completa** (in markdown) con:

* mapping **domande → dimensioni**
* massimi, normalizzazione, **Readiness score**
* regole per **Archetype**
* regole per **NOW Role / NEXT Role**
* algoritmo per scegliere i **Top 3 gap** + “micro-gap” (le domande più basse)
* template output (campi) da usare in Typeform / report

---

## A) Mappa scoring: domande → dimensioni

> Scala risposta: **0–4** (come già scritto).
> Q2 (ruolo target) = **metadato** (no punteggio).

| Q   | Nome                    | Dimensione            | Max |
| --- | ----------------------- | --------------------- | --- |
| Q1  | Esperienza              | Experience (modifier) | 4   |
| Q3  | Coding                  | Engineering           | 4   |
| Q4  | Backend/API             | Engineering           | 4   |
| Q5  | Frontend/UI             | Engineering           | 4   |
| Q6  | Git workflow            | Engineering           | 4   |
| Q7  | Qualità (test/standard) | Engineering           | 4   |
| Q8  | SQL & dati              | Data                  | 4   |
| Q9  | Fondamenti ML           | Data                  | 4   |
| Q10 | Misurazione/esperimenti | Data                  | 4   |
| Q11 | Problem framing         | Product               | 4   |
| Q12 | Scope & impatto         | Product               | 4   |
| Q13 | Writing tecnico         | Product               | 4   |
| Q14 | RAG                     | GenAI Systems         | 4   |
| Q15 | Prompting & output      | GenAI Systems         | 4   |
| Q16 | Agents                  | GenAI Systems         | 4   |
| Q17 | Eval LLM                | GenAI Systems         | 4   |
| Q18 | Deploy                  | GenAI Systems         | 4   |
| Q19 | Cost/Security/PII       | GenAI Systems         | 4   |
| Q20 | Proof pubblica          | Proof                 | 4   |

**Massimi per dimensione**

* Engineering: 5 domande → **max 20**
* Data: 3 domande → **max 12**
* Product: 3 domande → **max 12**
* GenAI Systems: 6 domande → **max 24**
* Proof: 1 domanda → **max 4**
* Experience: 1 domanda → **max 4** *(solo per “modifier”, non come dimensione principale)*

---

## B) Normalizzazione e Readiness Score (0–100)

### 1) Score normalizzato per dimensione

Per ogni dimensione:

**DimScore = (SommaRisposte / MaxDimensione) × 100**

Esempio:

* EngineeringScore = (Q3+Q4+Q5+Q6+Q7)/20 × 100

### 2) Readiness Score complessivo (pesato)

Consiglio questi pesi (coerenti col tuo positioning “prove concrete”):

* **Engineering 28%**
* **GenAI Systems 28%**
* **Proof 22%**
* **Product 12%**
* **Data 10%**

Formula:

**ReadinessBase = 0.28·Eng + 0.28·GenAI + 0.22·Proof + 0.12·Product + 0.10·Data**

### 3) Experience modifier (piccolo, ma utile)

Per evitare che 0 anni risulti “troppo alto” solo perché ha studiato bene:

* se Q1 = 0 → **−4 punti**
* se Q1 = 1 → **−2 punti**
* se Q1 = 2 → **0 punti**
* se Q1 = 3 → **+2 punti**
* se Q1 = 4 → **+4 punti**

**Readiness = clamp(ReadinessBase + ExpModifier, 0, 100)**

*(clamp = non scendere sotto 0 e non salire sopra 100)*

### 4) Etichette Readiness (label)

* **0–39** → “Not Ready”
* **40–54** → “Early Ready”
* **55–69** → “Ready (Junior)”
* **70–84** → “Strong Ready”
* **85–100** → “Offer-Competitive”

---

## C) Regole Archetype (basate sui 3 assi + tie-break)

Definisci 3 assi “identità” (quelli che mostri nel report):

* **Code Axis = EngineeringScore**
* **Data Axis = DataScore**
* **Product Axis = ProductScore**

### Decisione archetype

1. Ordina (Code, Data, Product) dal più alto al più basso.
2. Se (top − second) **≥ 12 punti** → archetype “puro”
3. Altrimenti → archetype “ibrido” (top + second)

**Archetype labels consigliati (semplici e chiari):**

* **Builder (Code-first)**
* **Data-Driven (Data-first)**
* **Product-Minded (Product-first)**
* **Hybrid: Builder + Data**
* **Hybrid: Builder + Product**
* **Hybrid: Data + Product**

### Tie-break (se sono vicinissimi)

Usa “GenAI Systems” per decidere il tag finale:

* se GenAI ≥ 60 → aggiungi badge “GenAI-ready mindset”
* se GenAI < 60 → badge “GenAI gap”

---

## D) Regole NOW Role / NEXT Role (logica deterministica)

> Input: Q2 (ruolo desiderato) è utile come preferenza, ma il sistema deve consigliare “NOW role” anche se l’utente non è sicuro.

### 1) Role profiles (soglie minime consigliate)

| Ruolo                            | Eng | GenAI              | Proof | Product | Data |
| -------------------------------- | --- | ------------------ | ----- | ------- | ---- |
| **LLM Apps Dev**                 | ≥60 | ≥45                | ≥40   | ≥45     | ≥25  |
| **RAG Dev**                      | ≥55 | ≥55 *(RAG+Eval)*   | ≥45   | ≥35     | ≥35  |
| **Applied GenAI (Eval/Quality)** | ≥40 | ≥55 *(Eval forte)* | ≥40   | ≥35     | ≥60  |
| **AI Product Engineer**          | ≥45 | ≥45                | ≥40   | ≥60     | ≥25  |
| **GenAI Engineer (E2E)**         | ≥65 | ≥65                | ≥55   | ≥45     | ≥35  |

Note pratiche:

* Per **RAG Dev** conta tantissimo Q14 (RAG) e Q17 (Eval): se uno dei due è <2, segnala gap critico.
* Per **GenAI Engineer** conta molto Q18 (Deploy) + Q19 (Reliability): se <2, non è “E2E”.

### 2) Selezione NOW Role (algoritmo)

1. Calcola per ogni ruolo un **FitScore**:

   * FitScore = media pesata delle dimensioni richieste
2. Se un ruolo fallisce **2+ soglie minime**, non può essere NOW (può essere NEXT).
3. NOW Role = ruolo con FitScore più alto tra quelli “ammissibili”.
4. Se nessun ruolo è ammissibile → NOW Role = “Prep Track” (costruire base + proof)

### 3) NEXT Role

NEXT Role = il ruolo “più ambizioso” compatibile **se** colmi i top 2 gap principali.
Tipicamente:

* se Eng alta e GenAI sale → NEXT = GenAI Engineer
* se Data alta e Eval sale → NEXT = Applied GenAI
* se Product alta e Proof sale → NEXT = AI Product Engineer

---

## E) Scelta Top 3 Gap (macro + micro)

### 1) Macro gap (dimensioni)

Regola base: seleziona i 3 gap **più rilevanti per il NOW Role**, non semplicemente i più bassi.

#### Matrice “priorità gap” per ruolo (ordine)

* **LLM Apps Dev:** Proof → GenAI → Product → Engineering → Data
* **RAG Dev:** GenAI → Proof → Engineering → Data → Product
* **Applied GenAI:** GenAI(Eval) → Data → Proof → Product → Engineering
* **AI Product Engineer:** Product → Proof → Engineering → GenAI → Data
* **GenAI Engineer:** GenAI → Engineering → Proof → Deploy/Reliability → Product

### 2) Come determinare i 3 gap in modo robusto

Per il ruolo scelto:

1. Prendi le dimensioni in ordine di priorità (tabella sopra).
2. Un “gap” scatta se la dimensione è sotto soglia:

   * **Critical:** <45
   * **Relevant:** 45–59
3. Se hai 2+ Critical, prendi prima quelli.
4. Completa fino a 3 gap con i Relevant più importanti.

### 3) Micro gap (domande specifiche)

Per ogni macro gap, seleziona le **2 domande più basse** dentro quella dimensione.

Esempi:

* Macro gap = GenAI → micro gap = tra Q14–Q19 prendi i 2 punteggi più bassi
* Macro gap = Engineering → micro gap = tra Q3–Q7 prendi i 2 più bassi

### 4) Output “Action” standard per micro-gap (template)

Per ogni micro-gap, il report deve dare:

* **Fix in 7 giorni**
* **Deliverable**
* **Criterio di completamento**

Esempio (micro-gap Q17 Eval bassa):

* Fix: crea test set 20 query + rubric pass/fail
* Deliverable: sheet + report 1 pagina
* Done when: puoi dimostrare miglioramento tra baseline e versione 2

---

## F) Campi output (template) per Typeform / report

### Campi minimi (FREE)

* `archetype_label`
* `readiness_score`
* `readiness_label`
* `axis_scores` (Code/Data/Product)
* `dimension_scores` (Eng/GenAI/Proof/Product/Data)
* `now_role`
* `top_3_gaps` (macro)
* `micro_gaps` (2 per macro)
* `next_step_one_liner` (1 frase)

### Campi BONUS (per chi applica / Career OS)

* `14_day_plan` (timeline con deliverable)
* `recommended_project` (1 progetto “flagship” coerente col ruolo)
* `templates_unlocked` (es. Eval Matrix / README Outline / Deploy checklist)
* `role_fit_snapshot` (perché quel ruolo, in 3 bullet)
* `application_strategy_hint` (es. target list + 10 candidature, ecc.)

---
